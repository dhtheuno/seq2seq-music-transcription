{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import run_length_encoding\n",
    "from data import event_codec\n",
    "from data import vocabularies\n",
    "from data import spectrograms\n",
    "from data import note_sequences\n",
    "import note_seq\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import sklearn\n",
    "from typing import Callable, Mapping, Optional, Sequence, Tuple\n",
    "import editdistance\n",
    "import mir_eval\n",
    "import librosa\n",
    "from utils import _audio_to_frames, AttrDict\n",
    "from model.ListenAttendSpell import ListenAttendSpell \n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import functools\n",
    "from evaluation import *\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/model.yaml', 'r') as f:\n",
    "    file_config = yaml.safe_load(f)\n",
    "config = AttrDict(file_config)\n",
    "config.training.beam_size = 2\n",
    "codec = event_codec.Codec(\n",
    "        max_shift_steps=300,\n",
    "        steps_per_second=100,\n",
    "        event_ranges=[\n",
    "                event_codec.EventRange('pitch', note_seq.MIN_MIDI_PITCH,\n",
    "                            note_seq.MAX_MIDI_PITCH),\n",
    "                event_codec.EventRange('velocity', 0, 127)\n",
    "        ])\n",
    "vocab = vocabularies.vocabulary_from_codec(codec)\n",
    "spectrogram_config = spectrograms.SpectrogramConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListenAttendSpell(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): LSTM(512, 1024, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(560, 512)\n",
       "    (rnn): ModuleList(\n",
       "      (0): LSTMCell(2560, 2048)\n",
       "    )\n",
       "    (attention): DotProductAttention()\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=2048, out_features=560, bias=True)\n",
       "    )\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_states = torch.load(\"/Users/donghyunlee/Desktop/encoder_decoder_model/test_data/las_model.epoch6399.chkpt\", map_location=torch.device('cpu'))\n",
    "model = ListenAttendSpell.load_model(model_states)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/Users/donghyunlee/Desktop/encoder_decoder_model/test_data/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_frames, segmented_times = segmentize_audio(audio_path, spectrogram_config)\n",
    "segmented_spec=[]\n",
    "for i in segmented_frames:\n",
    "    j = make_spectrogram(i, spectrogram_config)\n",
    "    segmented_spec.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 607/607 [1:06:45<00:00,  6.60s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_ns = make_pred_ns(segmented_spec, segmented_times, codec, vocab, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_path = '/Users/donghyunlee/Desktop/encoder_decoder_model/test_data/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav.midi'\n",
    "ref_ns = note_seq.midi_file_to_note_sequence(midi_path)\n",
    "note_sequences.validate_note_sequence(ref_ns)\n",
    "ref_ns = note_seq.apply_sustain_control_changes(ref_ns)\n",
    "output_1 = evaluation_mir_eval(ref_ns, pred_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Onset precision': 0.9843219231774236,\n",
       " 'Onset recall': 0.9543957436027363,\n",
       " 'Onset F1': 0.9691278621044507,\n",
       " 'Onset + offset precision': 0.7123072903057225,\n",
       " 'Onset + offset recall': 0.6906511274385609,\n",
       " 'Onset + offset F1': 0.7013120658605608,\n",
       " 'Onset + velocity precision': 0.9619806637052521,\n",
       " 'Onset + velocity recall': 0.932733721814036,\n",
       " 'Onset + velocity F1': 0.9471314638538719,\n",
       " 'Onset + offset + velocity precision': 0.6925790436373138,\n",
       " 'Onset + offset + velocity recall': 0.6715226754497087,\n",
       " 'Onset + offset + velocity F1': 0.6818883457679443}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "821f3860854be6a3325f5c12fafde2b8c9741f955fd2d720c03e1dc648762424"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
